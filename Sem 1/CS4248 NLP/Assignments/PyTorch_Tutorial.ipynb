{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSgudTeFKgYR"
   },
   "source": [
    "# Tensors\n",
    "(Taken and slightly modified from PyTorch official tutorial https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
    "In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "Tensors are similar to [NumPy’s](https://numpy.org/) ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and\n",
    "NumPy arrays can often share the same underlying memory, eliminating the need to copy data. Tensors are also optimized for **automatic differentiation** (we'll see more about that later in the [Autograd](autogradqs_tutorial.html)_\n",
    "section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ULK6YPJKYbi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaBSO10JK0W-"
   },
   "source": [
    "## Initializing a Tensor\n",
    "\n",
    "**Directly from data**\n",
    "\n",
    "Tensors can be created directly from python list. The data type is automatically inferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OR7O4dGjK4FC"
   },
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txESVGjsK6o-"
   },
   "source": [
    "**From a NumPy array**\n",
    "\n",
    "Tensors can be created from NumPy arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CpY28IQK9Vz"
   },
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nlvTnEmLBf6"
   },
   "source": [
    "**From another tensor:**\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tXTmCUwLAbX",
    "outputId": "0d882e77-7c47-4b53-ef26-eaefd25f63f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.8140, 0.9975],\n",
      "        [0.2747, 0.4374]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "y_ones = x_data.new_ones((1,2))  # retains the properties of x_data, but with a different size\n",
    "print(f\"Ones Tensor: \\n {y_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KRTOwkLtI6"
   },
   "source": [
    "**With random or constant values:**\n",
    "\n",
    "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LD52nzZLlkc",
    "outputId": "819766b6-2244-4009-a6b5-90231c3a8eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6031, 0.9020, 0.0404],\n",
      "        [0.2544, 0.5725, 0.2110]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Custom Tensor: \n",
      " tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "custom_tensor = torch.empty(shape).fill_(5)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
    "print(f\"Custom Tensor: \\n {custom_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9h3-hQgMZil"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcrMZTUdMPEm"
   },
   "source": [
    "## Attributes of a Tensor\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SN2zkRmiMD2T",
    "outputId": "28787889-e280-4973-d07b-7630b4f6dfea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B9i_02vMbSp"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDVQBaJWMoYW"
   },
   "source": [
    "## Operations on Tensors\n",
    "\n",
    "Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n",
    "indexing, slicing), sampling and more are\n",
    "comprehensively on PyTorch's documentation [here](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "Each of these operations can be run on the GPU (at typically higher speeds than on a\n",
    "CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n",
    "\n",
    "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n",
    "``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n",
    "across devices can be expensive in terms of time and memory!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6dbH0tcM47t",
    "outputId": "65aedfc0-9280-40ee-d6cd-90d225bf1ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available on this machine\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available on this machine\")\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5lTPXn4OXqn"
   },
   "source": [
    "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDTXI3zXOYbM"
   },
   "source": [
    "**Standard numpy-like indexing and slicing:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lQPxBylObVn",
    "outputId": "f98cd023-b399-48b4-b8f9-3b8eb12c654d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "farrnooDOjnh"
   },
   "source": [
    "**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
    "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_,\n",
    "another tensor joining op that is subtly different from ``torch.cat``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8Iv27jAOe5a",
    "outputId": "e8dde6cc-6a88-416f-da32-8614727403a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ankdS3JmOwcj"
   },
   "source": [
    "**Arithmetic operations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8YVc3qWOmHx",
    "outputId": "0905b4a6-d32e-42a8-998c-43c804fdbc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication:\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "Element-wise product\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "print('Matrix multiplication:')\n",
    "print(torch.matmul(tensor, tensor.T, out=y3))\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "print('Element-wise product')\n",
    "print(torch.mul(tensor, tensor, out=z3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A_tF6efQD83"
   },
   "source": [
    "**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n",
    "values of a tensor into one value, you can convert it to a Python\n",
    "numerical value using ``item()``:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qqhw9rlDO-K1",
    "outputId": "14445243-48d4-46f7-f06f-28ef6990a84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRsMkD-Qgeo"
   },
   "source": [
    "**In-place operations**\n",
    "Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n",
    "For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bs8f9TXiQXee",
    "outputId": "1899cc50-8cd9-4b97-c6b7-c03d63f9ae42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq02I_cvQrnM"
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPzzXddmQwlC"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OgFN_vWQxc8"
   },
   "source": [
    "\n",
    "## Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
    "locations, and changing one will change\tthe other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG_AX_pFQz5g"
   },
   "source": [
    "### Tensor to NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXX9sFjGRDyl",
    "outputId": "299f7b4c-f243-4170-c903-1d4696b11083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1JSGOJhREcN"
   },
   "source": [
    "A change in the tensor reflects in the NumPy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pya1hDAkRWFj",
    "outputId": "98dc32cf-554e-4ac3-b3b2-1563e330d715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPTN9sOURab3"
   },
   "source": [
    "### NumPy array to Tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWN9zItqRWi4"
   },
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xONN2w76R94V"
   },
   "source": [
    "Changes in the NumPy array reflects in the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edbhOQlTR9Rr",
    "outputId": "82c73569-e020-4999-b9c1-0aebee9f6ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izVkWxeVSOql"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C_K8qkNSjZT"
   },
   "source": [
    "\n",
    "# Deep Learning with PyTorch\n",
    "(taken and slightly modified from PyTorch official tutorial https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#sphx-glr-beginner-nlp-deep-learning-tutorial-py)\n",
    "\n",
    "## Deep Learning Building Blocks: Affine maps, non-linearities and objectives\n",
    "\n",
    "Deep learning consists of composing linearities with non-linearities in\n",
    "clever ways. The introduction of non-linearities allows for powerful\n",
    "models. In this section, we will play with these core components, make\n",
    "up an objective function, and see how the model is trained.\n",
    "\n",
    "\n",
    "### Affine Maps\n",
    "\n",
    "One of the core workhorses of deep learning is the affine map, which is\n",
    "a function $f(x)$ where\n",
    "\n",
    "\\begin{align}f(x) = xA^T + b\\end{align}\n",
    "\n",
    "for a matrix $A$ and vectors $x, b$. The parameters to be\n",
    "learned here are $A$ and $b$. Often, $b$ is refered to\n",
    "as the *bias* term.\n",
    "\n",
    "\n",
    "PyTorch and most other deep learning frameworks do things a little\n",
    "differently than traditional linear algebra. It maps the rows of the\n",
    "input instead of the columns. That is, the $i$'th row of the\n",
    "output below is the mapping of the $i$'th row of the input under\n",
    "$A$, plus the bias term. Look at the example below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qen2wSwZSB9k",
    "outputId": "60557d7d-4e34-4d91-9ca8-c5223d9c51e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdd6e2b5290>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5G8yJQJTLXh",
    "outputId": "c2b64388-030d-4798-c49d-64b1c6c18dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "tensor([[-1.1948,  0.0250, -0.7627,  1.3969, -0.3245],\n",
      "        [ 0.2879,  1.0579,  0.9621,  0.3935,  1.1322]])\n",
      "weight:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2304, -0.1974, -0.0867,  0.2099, -0.4210],\n",
      "        [ 0.2682, -0.0920,  0.2275,  0.0622, -0.0548],\n",
      "        [ 0.1240,  0.0221,  0.1633, -0.1743, -0.0326]], requires_grad=True)\n",
      "output:\n",
      "tensor([[ 0.1755, -0.3268, -0.5069],\n",
      "        [-0.6602,  0.2260,  0.1089]], grad_fn=<AddmmBackward0>)\n",
      "manual calculation:\n",
      "tensor([[ 0.1755, -0.3268, -0.5069],\n",
      "        [-0.6602,  0.2260,  0.1089]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = nn.Linear(5, 3)  # maps from R^5 to R^3, parameters A, b\n",
    "\n",
    "# data is 2x5.\n",
    "data = torch.randn(2, 5)\n",
    "print('input:')\n",
    "print(data)\n",
    "print('weight:')\n",
    "print(lin.weight)\n",
    "print('output:')\n",
    "print(lin(data))\n",
    "print('manual calculation:')\n",
    "print(torch.matmul(data, lin.weight.T) + lin.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjF773CSUgV2"
   },
   "source": [
    "### Non-Linearities\n",
    "\n",
    "Non-linear activation functions are necessary in building a neural network. Without the non-linear activations, for any n-layered neural network, we can find its equal single-layered neural network substitute.\n",
    "\n",
    "There are a few core non-linear actication functions.\n",
    "$\\tanh(x), \\sigma(x), \\text{ReLU}(x)$ are the most common. You are\n",
    "probably wondering: \"why these functions? I can think of plenty of other\n",
    "non-linearities.\" The reason for this is that they have gradients that\n",
    "are easy to compute, and computing gradients is essential for learning. The complete list of non-linear functions that PyTorch supported can be seen [here](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ior43etiUhBV",
    "outputId": "68effcfe-0eff-4667-c0f8-68f22c9b7aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5404, -2.2102],\n",
      "        [ 2.1130, -0.0040]])\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [2.1130, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# In pytorch, most non-linearities are in torch.functional (we have it imported as F)\n",
    "# Note that non-linearites typically don't have parameters like affine maps do.\n",
    "# That is, they don't have weights that are updated during training.\n",
    "data = torch.randn(2, 2)\n",
    "print(data)\n",
    "print(F.relu(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACku0nLsVCsS"
   },
   "source": [
    "### Softmax and Probabilities\n",
    "\n",
    "The function $\\text{Softmax}(x)$ is also just a non-linearity, but\n",
    "it is special in that it usually is the last operation done in a\n",
    "network. This is because it takes in a vector of real numbers and\n",
    "returns a probability distribution. Its definition is as follows. Let\n",
    "$x$ be a vector of real numbers (positive, negative, whatever,\n",
    "there are no constraints). Then the i'th component of\n",
    "$\\text{Softmax}(x)$ is\n",
    "\n",
    "\\begin{align}\\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\\end{align}\n",
    "\n",
    "It should be clear that the output is a probability distribution: each\n",
    "element is non-negative and the sum over all components is 1.\n",
    "\n",
    "You could also think of it as just applying an element-wise\n",
    "exponentiation operator to the input to make everything non-negative and\n",
    "then dividing by the normalization constant.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ri-SBNDgU7_I",
    "outputId": "090b5f57-a646-48cf-f5f1-53436647beca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3800, -1.3505,  0.3455,  0.5046,  1.8213])\n",
      "tensor([0.2948, 0.0192, 0.1048, 0.1228, 0.4584])\n",
      "tensor(1.)\n",
      "tensor([-1.2214, -3.9519, -2.2560, -2.0969, -0.7801])\n"
     ]
    }
   ],
   "source": [
    "# Softmax is also in torch.nn.functional\n",
    "data = torch.randn(5)\n",
    "print(data)\n",
    "print(F.softmax(data, dim=0))\n",
    "print(F.softmax(data, dim=0).sum())  # Sums to 1 because it is a distribution!\n",
    "print(F.log_softmax(data, dim=0))  # there's also log_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG9Zm0bIf8np"
   },
   "source": [
    "## Example Task: Language Identification\n",
    "\n",
    "Let's write an annotated example of a network that takes in a sparse\n",
    "bag-of-words representation and outputs a probability distribution over\n",
    "two labels: \"English\" and \"Spanish\". We will use a simple model, just logistic\n",
    "regression, but implemented in PyTorch. Let's first define the task and the data, then we see how we build the model, compute the loss function, and update the parameters by backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFnzqXhqhNGK"
   },
   "outputs": [],
   "source": [
    "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "\n",
    "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "             (\"it is lost on me\".split(), \"ENGLISH\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71Gs9xkCh0md"
   },
   "source": [
    "### Data Representation\n",
    "Neural network only deals with numerical data. If you have textual input, you need to convert it into a numerical input. The same goes for categorical labels. Let's make our data numerical by first mapping each word and label into the word index and label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxJxLNp3hzHM",
    "outputId": "8c0f72f6-c9c5-4715-f535-ee8aee7c46b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22}\n",
      "{'SPANISH': 0, 'ENGLISH': 1}\n"
     ]
    }
   ],
   "source": [
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
    "# index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "for sent, _ in data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "\n",
    "label_to_ix = {}\n",
    "for _, label in data:\n",
    "    if label not in label_to_ix:\n",
    "        label_to_ix[label] = len(label_to_ix)\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "print(label_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_AHw9yfi9dx"
   },
   "source": [
    "There are many ways to represent textual feature for machine learning training. One of the most popular feature representation that we have learned is bag-of-words. Here, we will convert the input data into a tensor of bag of words and the label into a tensor of label indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuvWIrLGkj8v"
   },
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        if word in word_to_ix:\n",
    "            vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPM6oDlvWEJz"
   },
   "source": [
    "### Creating Network Components in PyTorch\n",
    "\n",
    "All network components should inherit from nn.Module and override the\n",
    "forward() method. That is about it, as far as the boilerplate is\n",
    "concerned. Inheriting from nn.Module provides functionality to your\n",
    "component.\n",
    "\n",
    "To accelerate the training, we should place our model in the GPU instead of the CPU. We can do that with the same ``.to(device)`` command that we have learned in the Tensor section. After that command is invoked, all modules and tensors that are initialized in the constructor (______init__) of the model will be placed in GPU. However, note that new tensors that are initialized in other locations (e.g., ``forward`` function) will by default be stored in CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpRKMC2VWSBb",
    "outputId": "50802d93-fb66-4a7f-8aef-af70fc73a9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1270,  0.0647, -0.1348,  0.1354,  0.1266,  0.1849, -0.1169, -0.0343,\n",
      "         -0.0040,  0.0305, -0.1582, -0.1480,  0.1134, -0.0489,  0.1019,  0.0119,\n",
      "          0.0685,  0.0458,  0.0758,  0.1034, -0.1931,  0.1050, -0.1466],\n",
      "        [-0.1573,  0.0127, -0.0355,  0.1225, -0.1208, -0.1854,  0.1518, -0.0309,\n",
      "          0.1173,  0.0670, -0.1564,  0.0419,  0.0501, -0.1396, -0.0989,  0.0711,\n",
      "          0.0373, -0.0887, -0.0631,  0.1910, -0.0386,  0.1176,  0.0903]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1348, -0.1773], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# the model knows its parameters.  The first output below is A, the second is b.\n",
    "# Whenever you assign a component to a class variable in the __init__ function\n",
    "# of a module, which was done with the line\n",
    "# self.linear = nn.Linear(...)\n",
    "# Then through some Python magic from the PyTorch devs, your module\n",
    "# (in this case, BoWClassifier) will store knowledge of the nn.Linear's parameters\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBZYfsNNY3Mz"
   },
   "source": [
    "### Training Procedure\n",
    "\n",
    "The deep learning training goal is to minimize the objective function of the network (in which case it is often called a *loss function*\n",
    "or *cost function*). This proceeds by:\n",
    "1. Choose a training instance.\n",
    "2. Run it through your neural network.\n",
    "3. Compute the loss of the output.\n",
    "4. Update the parameters of the model are by taking the derivative of the loss function.\n",
    "\n",
    "Intuitively,\n",
    "- If your model is very confident in its answer, and its answer is wrong, your loss will be high.\n",
    "- If your model is very confident in its answer, and its answer is correct, the loss will be low.\n",
    "- If your model is not very confident in its answer, it's somewhere in between.\n",
    "\n",
    "The idea behind minimizing the loss function on your training examples\n",
    "is that your network will **hopefully generalize well** and have small loss\n",
    "on unseen examples in your dev set, test set, or in production. An\n",
    "example loss function is the [*negative log likelihood loss*](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html), which is a\n",
    "very common objective for multi-class classification. For supervised\n",
    "multi-class classification, this means training the network to minimize\n",
    "the negative log probability of the correct output (or equivalently,\n",
    "maximize the log probability of the correct output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1CC0vmgXWy0"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss() # similar to cross entropy but accepts log-probabilities as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_Wm4BRWbHvT"
   },
   "source": [
    "### Optimization\n",
    "\n",
    "What do we do with the loss of the model? Well, since our loss is an Tensor, we can compute gradients with respect to all of the parameters used to compute it! Then we can perform standard **gradient updates**. Let $\\theta$ be our parameters,\n",
    "$L(\\theta)$ the loss function, and $\\eta$ a positive\n",
    "learning rate. Then:\n",
    "\n",
    "\\begin{align}\\theta^{(t+1)} = \\theta^{(t)} - \\eta \\nabla_\\theta L(\\theta)\\end{align}\n",
    "\n",
    "You don't need to worry about calculating the gradient (or the derivation of the loss function), PyTorch will automatically calculate it for you (if you are curious, learn more about [PyTorch autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)).\n",
    "\n",
    "\n",
    "There are a huge collection of algorithms and active research for the gradient update. Torch provides many in the [torch.optim](https://pytorch.org/docs/stable/optim.html) package, and they are all completely transparent. Using the simplest gradient update is the same as the more complicated algorithms. Trying different update algorithms and different parameters for the update algorithms (like different initial learning rates) is important in optimizing your network's performance. Often, just replacing vanilla SGD with an optimizer like Adam or RMSProp will boost performance noticably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVWgo4LLaBl6"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK5LTNP3fchD"
   },
   "source": [
    "### Training and Testing\n",
    "\n",
    "Transform the input into the model feature, then feed it into the model to get the label (log-probabilities of the identified languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMAQtpCDfQoa",
    "outputId": "fd158b46-34f8-419b-d651-830b19579d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probs: tensor([[-0.7705, -0.6213]], device='cuda:0')\n",
      "predicted: ENGLISH, actual label: SPANISH\n",
      "log probs: tensor([[-0.5367, -0.8787]], device='cuda:0')\n",
      "predicted: SPANISH, actual label: ENGLISH\n",
      "tensor([-0.1480,  0.0419], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ix_to_labels = list(label_to_ix.keys())\n",
    "\n",
    "def test(instance, vocab):\n",
    "    with torch.no_grad():\n",
    "        bow_vec = make_bow_vector(instance, vocab)\n",
    "        bow_vec = bow_vec.to(device)\n",
    "        log_probs = model(bow_vec)\n",
    "        return log_probs\n",
    "\n",
    "# Run on test data before we train, just to see a before-and-after\n",
    "for instance, label in test_data:\n",
    "    log_probs = test(instance, word_to_ix)\n",
    "    pred_label = ix_to_labels[torch.argmax(log_probs.squeeze()).item()]\n",
    "    print(f\"log probs: {log_probs}\")\n",
    "    print(f\"predicted: {pred_label}, actual label: {label}\")\n",
    "\n",
    "# Print the matrix column corresponding to \"que\"\n",
    "print(next(model.parameters())[:, word_to_ix[\"que\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I70FEEjvHrBq"
   },
   "source": [
    "Predicting the test labels before the training results in the model predicting English for both sentences. Furthermore, the weights for the word _que_ are all close to 0, with a slight tendency toward being predicted as English (the first index is bigger than the 0-th index, ``0.0419 > -0.1480``).\n",
    "\n",
    "Now, let's train the model for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWRsPigAoMtA",
    "outputId": "65b36564-a38e-4b07-9f53-4940d9fb8182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on epoch 0: 2.33\n",
      "Loss on epoch 1: 1.50\n",
      "Loss on epoch 2: 1.09\n",
      "Loss on epoch 3: 0.85\n",
      "Loss on epoch 4: 0.70\n",
      "Loss on epoch 5: 0.59\n",
      "Loss on epoch 6: 0.51\n",
      "Loss on epoch 7: 0.45\n",
      "Loss on epoch 8: 0.40\n",
      "Loss on epoch 9: 0.36\n",
      "Loss on epoch 10: 0.33\n",
      "Loss on epoch 11: 0.31\n",
      "Loss on epoch 12: 0.28\n",
      "Loss on epoch 13: 0.26\n",
      "Loss on epoch 14: 0.25\n",
      "Loss on epoch 15: 0.23\n",
      "Loss on epoch 16: 0.22\n",
      "Loss on epoch 17: 0.21\n",
      "Loss on epoch 18: 0.19\n",
      "Loss on epoch 19: 0.18\n",
      "Loss on epoch 20: 0.18\n",
      "Loss on epoch 21: 0.17\n",
      "Loss on epoch 22: 0.16\n",
      "Loss on epoch 23: 0.15\n",
      "Loss on epoch 24: 0.15\n",
      "Loss on epoch 25: 0.14\n",
      "Loss on epoch 26: 0.14\n",
      "Loss on epoch 27: 0.13\n",
      "Loss on epoch 28: 0.13\n",
      "Loss on epoch 29: 0.12\n",
      "Loss on epoch 30: 0.12\n",
      "Loss on epoch 31: 0.12\n",
      "Loss on epoch 32: 0.11\n",
      "Loss on epoch 33: 0.11\n",
      "Loss on epoch 34: 0.11\n",
      "Loss on epoch 35: 0.10\n",
      "Loss on epoch 36: 0.10\n",
      "Loss on epoch 37: 0.10\n",
      "Loss on epoch 38: 0.09\n",
      "Loss on epoch 39: 0.09\n",
      "Loss on epoch 40: 0.09\n",
      "Loss on epoch 41: 0.09\n",
      "Loss on epoch 42: 0.09\n",
      "Loss on epoch 43: 0.08\n",
      "Loss on epoch 44: 0.08\n",
      "Loss on epoch 45: 0.08\n",
      "Loss on epoch 46: 0.08\n",
      "Loss on epoch 47: 0.08\n",
      "Loss on epoch 48: 0.08\n",
      "Loss on epoch 49: 0.07\n",
      "Loss on epoch 50: 0.07\n",
      "Loss on epoch 51: 0.07\n",
      "Loss on epoch 52: 0.07\n",
      "Loss on epoch 53: 0.07\n",
      "Loss on epoch 54: 0.07\n",
      "Loss on epoch 55: 0.07\n",
      "Loss on epoch 56: 0.06\n",
      "Loss on epoch 57: 0.06\n",
      "Loss on epoch 58: 0.06\n",
      "Loss on epoch 59: 0.06\n",
      "Loss on epoch 60: 0.06\n",
      "Loss on epoch 61: 0.06\n",
      "Loss on epoch 62: 0.06\n",
      "Loss on epoch 63: 0.06\n",
      "Loss on epoch 64: 0.06\n",
      "Loss on epoch 65: 0.06\n",
      "Loss on epoch 66: 0.06\n",
      "Loss on epoch 67: 0.05\n",
      "Loss on epoch 68: 0.05\n",
      "Loss on epoch 69: 0.05\n",
      "Loss on epoch 70: 0.05\n",
      "Loss on epoch 71: 0.05\n",
      "Loss on epoch 72: 0.05\n",
      "Loss on epoch 73: 0.05\n",
      "Loss on epoch 74: 0.05\n",
      "Loss on epoch 75: 0.05\n",
      "Loss on epoch 76: 0.05\n",
      "Loss on epoch 77: 0.05\n",
      "Loss on epoch 78: 0.05\n",
      "Loss on epoch 79: 0.05\n",
      "Loss on epoch 80: 0.05\n",
      "Loss on epoch 81: 0.05\n",
      "Loss on epoch 82: 0.04\n",
      "Loss on epoch 83: 0.04\n",
      "Loss on epoch 84: 0.04\n",
      "Loss on epoch 85: 0.04\n",
      "Loss on epoch 86: 0.04\n",
      "Loss on epoch 87: 0.04\n",
      "Loss on epoch 88: 0.04\n",
      "Loss on epoch 89: 0.04\n",
      "Loss on epoch 90: 0.04\n",
      "Loss on epoch 91: 0.04\n",
      "Loss on epoch 92: 0.04\n",
      "Loss on epoch 93: 0.04\n",
      "Loss on epoch 94: 0.04\n",
      "Loss on epoch 95: 0.04\n",
      "Loss on epoch 96: 0.04\n",
      "Loss on epoch 97: 0.04\n",
      "Loss on epoch 98: 0.04\n",
      "Loss on epoch 99: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Usually you want to pass over the training data several times.\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for instance, label in data:\n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix).to(device)\n",
    "        target = make_target(label, label_to_ix).to(device)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Loss on epoch {epoch}: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3rzSUhQo2Lg"
   },
   "source": [
    "Let's check the performance again after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvqqZkCeoxgg",
    "outputId": "8d1b20ad-fd31-49d9-8fb7-38bd25791c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probs: tensor([[-0.1765, -1.8214]], device='cuda:0')\n",
      "predicted: SPANISH, actual label: SPANISH\n",
      "log probs: tensor([[-2.3982, -0.0953]], device='cuda:0')\n",
      "predicted: ENGLISH, actual label: ENGLISH\n",
      "tensor([ 0.2760, -0.3821], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run on test data before we train, just to see a before-and-after\n",
    "for instance, label in test_data:\n",
    "    log_probs = test(instance, word_to_ix)\n",
    "    pred_label = ix_to_labels[torch.argmax(log_probs.squeeze()).item()]\n",
    "    print(f\"log probs: {log_probs}\")\n",
    "    print(f\"predicted: {pred_label}, actual label: {label}\")\n",
    "\n",
    "# Print the matrix column corresponding to \"que\"\n",
    "print(next(model.parameters())[:, word_to_ix[\"que\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKZJWHosIPF1"
   },
   "source": [
    "After training the model to convergences, the model can now predict the test sentences accurately. Now, the weight for the word _que_ have a much bigger tendency toward being predicted as Spanish (the 0-th index is much bigger than the 1st index, ``0.2760 > -0.3821``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0huJh0eiSPrz"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01GBmg6suE_2"
   },
   "source": [
    "## Save and Load the Model\n",
    "(taken and slightly modified from PyTorch official tutorial https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe7oHiNByhYy"
   },
   "source": [
    "PyTorch models store the learned parameters in an internal\n",
    "state dictionary, called ``state_dict``. These can be persisted via the ``torch.save``\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GY-Wn5JhyVr1"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'model_weights.pth'\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2x7tAN6MyxY8"
   },
   "source": [
    "To load model weights, you need to create an instance of the same model first, and then load the parameters\n",
    "using ``load_state_dict()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUr5zTq2ypfU",
    "outputId": "8212fc2d-f49f-46f4-c1ab-334c7e11d5ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wv9-Pzj8zA6J"
   },
   "source": [
    "As PyTorch model's ``state_dict()`` is a dictionary, we can save the model's weight with other helpful information to continue the training or to the test the model, like optimizer's ``state_dict()``, hyper-parameters, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_dW82uzzmon"
   },
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "              'epoch': epoch,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': loss,\n",
    "              }\n",
    "torch.save(checkpoint, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD4uQyRBuKOa"
   },
   "source": [
    "For a more detailed information on PyTorch's saving and loading model, please refer to https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "(Note that this is a different link from the top one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyUt5wRYtwR2"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiMslF25Asrh"
   },
   "source": [
    "# Datasets and Dataloaders\n",
    "To easily maintain our code, ideally we decouple the code to process the data, the code to run the training, and the model itself. PyTorch encourages users to use two of their data classes, **Dataset** and **DataLoader**.\n",
    "* Dataset class is used to load the data and pre-process the data.\n",
    "* DataLoader class is used to sample and aggregate the data (create the mini-batch) from the Dataset class during training and testing.\n",
    "* The training/testing script will loop over the DataLoader object to get the training/testing mini-batches.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJtekvgyLnGM"
   },
   "source": [
    "![dataset.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNGpS0wjLmrX"
   },
   "source": [
    "\n",
    "PyTorch provides many well known datasets for Computer Vision tasks (https://pytorch.org/vision/stable/datasets.html) and NLP tasks (https://pytorch.org/text/stable/datasets.html). When working with our own data, we need to create a custom dataset class that extends the PyTorch Dataset class.\n",
    "\n",
    "When implementing our own custom dataset, the class needs to implement two functions: \n",
    "- ______len__ : the function that returns the dataset size.\n",
    "- ______getitem__ : the function that accepts an index and returns the processed data in that index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmO9d-u7AUcP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LangDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class to load and pre-process the data of\n",
    "    language identification task\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, vocab=None, is_training=True):\n",
    "        # ideally load from the data_path\n",
    "        raw_data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "                    (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "                    (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "                    (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "        self.texts = [x[0] for x in raw_data]\n",
    "        self.labels = [x[1] for x in raw_data]\n",
    "        if is_training:\n",
    "            self.text_vocab = self.create_text_vocab(self.texts)\n",
    "            self.label_vocab = self.create_label_vocab(self.labels)\n",
    "        else:\n",
    "            assert vocab is not None, \"testing must use vocab from training\"\n",
    "            self.text_vocab = vocab['text']\n",
    "            self.label_vocab = vocab['labels']\n",
    "        \n",
    "        self.texts = [self.make_bow_vector(x) for x in self.texts]\n",
    "        self.labels = [self.make_target(y) for y in self.labels]\n",
    "\n",
    "\n",
    "    def create_text_vocab(self, data):\n",
    "        text_vocab = {}\n",
    "        for sent in data:\n",
    "            for word in sent:\n",
    "                if word not in text_vocab:\n",
    "                    text_vocab[word] = len(text_vocab)\n",
    "        \n",
    "        return text_vocab\n",
    "\n",
    "\n",
    "    def create_label_vocab(self, data):\n",
    "        label_vocab = {}\n",
    "        for label in data:\n",
    "            if label not in label_vocab:\n",
    "                label_vocab[label] = len(label_vocab)\n",
    "        \n",
    "        return label_vocab\n",
    "\n",
    "\n",
    "    def make_bow_vector(self, data):\n",
    "        vec = torch.zeros(len(self.text_vocab))\n",
    "        for word in data:\n",
    "            vec[self.text_vocab[word]] += 1\n",
    "        return vec.view(1, -1)\n",
    "\n",
    "\n",
    "    def make_target(self, label):\n",
    "        return torch.LongTensor([self.label_vocab[label]])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihyqneHkRZqv",
    "outputId": "91143e3e-9b1e-4843-a65f-5634932de585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0.]]), tensor([0]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LangDataset('path_to_file')\n",
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EC1zbtNj1NM0"
   },
   "source": [
    "Dataset object is an python iterable class, means that we can loop over the dataset object to get each of the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZPOS-qy0sfg",
    "outputId": "56f32a4c-5a0d-4863-9274-13d23895e808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0\n",
      "Text: tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]])\n",
      "Label: tensor([0])\n",
      "\n",
      "Instance 1\n",
      "Text: tensor([[1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]])\n",
      "Label: tensor([1])\n",
      "\n",
      "Instance 2\n",
      "Text: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]])\n",
      "Label: tensor([0])\n",
      "\n",
      "Instance 3\n",
      "Text: tensor([[0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1.]])\n",
      "Label: tensor([1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    text, label = dataset.__getitem__(i)\n",
    "    print(f\"Instance {i}\")\n",
    "    print(f\"Text: {text}\\nLabel: {label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ita3bvoGCsS8"
   },
   "source": [
    "Since all outputs of the ______getitem__ above have same shapes, we can easily create a mini batch from our dataset object by using PyTorch's DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEFEU98lRqZm",
    "outputId": "b20b0902-ff5b-4d77-9e40-6049897a8952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0\n",
      "Text: tensor([[[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n",
      "Label: tensor([[0],\n",
      "        [1]])\n",
      "\n",
      "Instance 1\n",
      "Text: tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1.]]])\n",
      "Label: tensor([[0],\n",
      "        [1]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "for i, instance in enumerate(dataloader):\n",
    "    text, label = instance\n",
    "    print(f\"Instance {i}\")\n",
    "    print(f\"Text: {text}\\nLabel: {label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCUNY4jI17aR"
   },
   "source": [
    "We almost never need to implement our own DataLoader class, but may need to implement our custom collator function if the dataset's ______getitem__ outputs are not in the type PyTorch tensors or have different shapes. Learn more about PyTorch Dataset and DataLoader class here: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoSiWqt1DqQj"
   },
   "source": [
    "# Closing\n",
    "This tutorial already covers all PyTorch basics for implementing simple neural model for NLP tasks. Familiarize yourself with PyTorch [documentation](https://pytorch.org/docs/stable/index.html) to understand more about its functions and how to use them.\n",
    "\n",
    "If you have any questions about this tutorial, you can contact me through email (mrqorib@u.nus.edu)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
