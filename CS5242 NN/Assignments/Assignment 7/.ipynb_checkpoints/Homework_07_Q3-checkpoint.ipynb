{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n_Je_X2yzOt"
   },
   "source": [
    "# Welcome to CS 5242 **Homework 7**\n",
    "\n",
    "ASSIGNMENT DEADLINE ⏰ : **6 Nov 2022, 23:59**\n",
    "\n",
    "In this assignment, we have three questions. This is the third question and please write the answer in this notebook.\n",
    "\n",
    "Colab is a hosted Jupyter notebook service that requires no setup to use, while providing access free of charge to computing resources including GPUs. In this semester, we will use Colab to run our experiments.\n",
    "\n",
    "### **Grades Policy**\n",
    "\n",
    "We have 10 points for this homework. 15% off per day late, 0 scores if you submit it 7 days after the deadline.\n",
    "\n",
    "### **Cautions**\n",
    "\n",
    "**DO NOT** copy the code from the internet, e.g. GitHub.\n",
    "\n",
    "**DO NOT** use external libraries like Tensorflow, keras in your implementation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Contact**\n",
    "\n",
    "Please feel free to contact us if you have any question about this homework or need any further information.\n",
    "\n",
    "Slack (Recommend): Lin Qiuxia\n",
    "\n",
    "TA Email: qiuxia.lin@u.nus.edu\n",
    "\n",
    "> If you have not join the slack group, you can click [here](https://join.slack.com/t/cs5242ay20222-oiw1784/shared_invite/zt-1eiv24k1t-0J9EI7vz3uQmAHa68qU0aw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsSR6XdA_J_U"
   },
   "source": [
    "# Question 3 (3 Points)\n",
    "In this question, we will implement a Deep Convolutional GANs to generate face images. \n",
    "\n",
    "Most codes are provided and a few codes are missing. Please enter your codes in the highlighted parts and run all the cells to provide proper outputs. \n",
    "\n",
    "Feel free to adjust model hyperparameter values when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wI3WwhKvfHgm",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/rbajpdlh7efkdo1/male_female_face_images.zip\n",
    "!unzip -q male_female_face_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WeJpNSnLfLr5",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'multiprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install -q --upgrade torch_snippets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_snippets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch_snippets/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.499.5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarkup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch_snippets/loader.py:74\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlank\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m ]\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbb_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch_snippets/logger.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsole\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Console\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtheme\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Theme\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m patch_to\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/loguru/__init__.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _defaults\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Core \u001b[38;5;28;01mas\u001b[39;00m _Core\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger \u001b[38;5;28;01mas\u001b[39;00m _Logger\n\u001b[1;32m     13\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.6.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/loguru/_logger.py:84\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isclass, iscoroutinefunction, isgeneratorfunction\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m current_process\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m basename, splitext\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m current_thread\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'multiprocessing'"
     ]
    }
   ],
   "source": [
    "!pip3 install -q --upgrade torch_snippets\n",
    "from torch_snippets import *\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import cv2, numpy as np, pandas as pd\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxnHjD0bfNnP",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4toje9ZyfPJw",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir cropped_faces\n",
    "images = Glob('/content/females/*.jpg')+Glob('/content/males/*.jpg')\n",
    "for i in range(len(images)):\n",
    "    img = read(images[i],1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img2 = img[y:(y+h),x:(x+w),:]\n",
    "    cv2.imwrite('cropped_faces/'+str(i)+'.jpg',cv2.cvtColor(img2, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqeA3FRrfRaW",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                               transforms.Resize(64),\n",
    "                               transforms.CenterCrop(64),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iSU5PzTfhlu",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Faces(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.images = sorted(Glob(folder))\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self, ix):\n",
    "        image_path = self.images[ix]\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX1o-X16fil0",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds = Faces(folder='cropped_faces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M27gcVo8f5ei",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ds, batch_size=64, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pst13pIvf8vy",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ###################################\n",
    "            ###Please enter your codes here####\n",
    "            ###################################\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            ####################################\n",
    "        )\n",
    "   \n",
    "    def forward(self, input): return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FV_-iDJGf-53",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch_summary\n",
    "from torchsummary import summary\n",
    "discriminator = Discriminator().to(device)\n",
    "summary(discriminator,torch.zeros(1,3,64,64));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYZZuAW-gAvU",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ###################################\n",
    "            ###Please enter your codes here####\n",
    "            ###################################\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "            ####################################\n",
    "        )\n",
    "   \n",
    "    def forward(self,input): return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPLs8OQLgD0-",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "summary(generator,torch.zeros(1,100,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMmN1_K8gFr7",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(real_data, fake_data):\n",
    "    d_optimizer.zero_grad()\n",
    "    prediction_real = discriminator(real_data)\n",
    "    error_real = loss(prediction_real.squeeze(), torch.ones(len(real_data)).to(device))\n",
    "    error_real.backward()\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    error_fake = loss(prediction_fake.squeeze(), torch.zeros(len(fake_data)).to(device))\n",
    "    error_fake.backward()\n",
    "    d_optimizer.step()\n",
    "    return error_real + error_fake\n",
    "\n",
    "def generator_train_step(fake_data):\n",
    "    g_optimizer.zero_grad()\n",
    "    prediction = discriminator(fake_data)\n",
    "    error = loss(prediction.squeeze(), torch.ones(len(real_data)).to(device))\n",
    "    error.backward()\n",
    "    g_optimizer.step()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vejwiYhwgIe4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "loss = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # Feel free to adjust the optimizer hyperparameters\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # Feel free to adjust the optimizer hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4YuDDoLgKOc",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "log = Report(25)\n",
    "for epoch in range(25):\n",
    "    N = len(dataloader)\n",
    "    for i, images in enumerate(dataloader):\n",
    "        real_data = images.to(device)\n",
    "        fake_data = generator(torch.randn(len(real_data), 100, 1, 1).to(device)).to(device)\n",
    "        fake_data = fake_data.detach()\n",
    "        d_loss = discriminator_train_step(real_data, fake_data)\n",
    "        fake_data = generator(torch.randn(len(real_data), 100, 1, 1).to(device)).to(device)\n",
    "        g_loss = generator_train_step(fake_data)\n",
    "        log.record(epoch+(1+i)/N, d_loss=d_loss.item(), g_loss=g_loss.item(), end='\\r')\n",
    "\n",
    "log.plot_epochs(['d_loss','g_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blr9dMTOgSZZ",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "sample_images = generator(noise).detach().cpu()\n",
    "grid = vutils.make_grid(sample_images, nrow=8, normalize=True)\n",
    "show(grid.cpu().detach().permute(1,2,0), sz=10, title='Generated images')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
