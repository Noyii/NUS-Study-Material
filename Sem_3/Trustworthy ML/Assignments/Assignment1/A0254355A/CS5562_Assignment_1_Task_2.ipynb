{"cells":[{"cell_type":"markdown","metadata":{"id":"GH1iAczDVRjJ"},"source":["# Task 2: Input Randomization"]},{"cell_type":"markdown","metadata":{"id":"U8tKsxW5oYTj"},"source":["### If you are using Google Colab, you need to upload this notebook and the codebase to your Google Drive. Then you need to mount your Google Drive in Colab and set your working directory. If you are running on your local machine, you can ignore the following line."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WREld4LanEkm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693592847535,"user_tz":-480,"elapsed":17856,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"779182db-3c7b-4998-ea42-74b86f485011"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWxeNJwv6kW9"},"outputs":[],"source":["import os\n","root_dir = \"/content/drive/My Drive/\"\n","project_dir = \"Assignment1_code\" # Change to your path\n","os.chdir(root_dir + project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FDukDiM7q7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693592847535,"user_tz":-480,"elapsed":5,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"17ed2551-8ffe-477f-9b05-560a593a11b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["CS5562_Assignment_1_Task_1.ipynb    imagenet_class_index.json\n","CS5562_Assignment_1_Task_2.ipynb    JSMA\n","CS5562_Assignment_1_Task_3.ipynb    model.py\n","CS5562_Assignment_1_Task_4.ipynb    __pycache__\n","CS5562_Assignment_1_Task_5.ipynb    results\n","CS5562_Assignment_1_Warm_ups.ipynb  test_image\n","defense.py\t\t\t    utilities.py\n","environment.yml\n"]}],"source":["# Make sure the path is correct\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"BK-LWx5SYZVk"},"source":["## Implement the Defense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlLOrDdOAwuK"},"outputs":[],"source":["from torchvision import transforms\n","import torch\n","from scipy.stats import norm, binom_test\n","import numpy as np\n","from math import ceil\n","from statsmodels.stats.proportion import proportion_confint\n","import torch.nn as nn\n","import torchvision\n","from torch import optim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSIOGqOFVUXb"},"outputs":[],"source":["def randomization_input(test_image, resize_bound):\n","    '''\n","    :param test_image: the test image which could be clean or adversarial. The size is [1, 3, 224,224]\n","    :return: randomized version of the test image. The size is [1, 3, resize_bound, resize_bound].\n","    Hints:\n","    1. Sample a integer number uniformly from [1,10]: np.random.randint(1,10, size=1)\n","    2. Pytorch provides transforms function for image transformations. You can call the transforms.Resize to resize your images (https://pytorch.org/vision/stable/transforms.html).\n","    >>> p = transforms.Compose([transforms.Resize(48)])\n","    >>> p(test_image)\n","    3. Pytorch provides torch.nn.functional.pad function to pad tensors.\n","    '''\n","\n","    PAD_VALUE = 0.5  # this is the pad value for the random padding step\n","    randomized_image = test_image\n","    ################\n","    # TODO: implement randomized resizing and randomized padding.\n","    rand_W, rand_H = np.random.randint(low=224, high=resize_bound, size=2)\n","\n","    ## Resizing between [224, resize_bound) for least performance drop in clean images.\n","    resized_image = transforms.Resize(size=(rand_H, rand_W))(randomized_image)\n","\n","    ## Padding - (padding_left, padding_right, padding_top, padding_bottom)\n","    leftover_W = resize_bound - rand_W\n","    leftover_H = resize_bound - rand_H\n","    prob_w, prob_h = np.random.randint(0, 11, size=2)\n","\n","    left = int(leftover_W * prob_w/10)\n","    right = leftover_W - left\n","    top = int(leftover_H * prob_h/10)\n","    bottom = leftover_H - top\n","\n","    pad = (left, right, top, bottom)\n","    randomized_image = nn.functional.pad(resized_image, pad, \"constant\", PAD_VALUE)\n","    assert randomized_image.shape == torch.Size([1, 3, resize_bound, resize_bound]), ValueError('Shape does not match')\n","\n","    ################\n","    return randomized_image"]},{"cell_type":"markdown","metadata":{"id":"251xII65ClJQ"},"source":["## Test your code"]},{"cell_type":"markdown","metadata":{"id":"PQJdCJDBZpcc"},"source":["#### Copy and Paste your FSGM and PGD attacks here:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-GwKL23Z1W6"},"outputs":[],"source":["class FSG_attack:\n","    \"\"\"\n","        The FSGM attack in warm-up task.\n","    \"\"\"\n","    def __init__(self, target_model: torchvision.models, epsilon: float):\n","        self.target_model = target_model\n","        self.epsilon = epsilon\n","\n","    def attack(self, test_image: torch.tensor, y_true: torch.tensor, is_targeted: bool = False,\n","               y_target: torch.tensor = None)-> torch.tensor:\n","        perturbation = torch.zeros_like(test_image, requires_grad=True)  # init the perturbation\n","        pred = self.target_model.predict(test_image + perturbation)\n","\n","        if is_targeted:\n","            ############\n","            # TODO: implement the loss\n","            criterion = torch.nn.CrossEntropyLoss()\n","            loss = -criterion(pred, y_target)\n","            ############\n","        else:\n","            ############\n","            # TODO: implement the loss function\n","            criterion = torch.nn.CrossEntropyLoss()\n","            loss = criterion(pred, y_true)\n","            ############\n","\n","        loss.backward()\n","        gradient = perturbation.grad  # get the gradient of the loss with respect to the perturbation\n","        ############\n","        # TODO: update the perturbation\n","        perturbation = self.epsilon * torch.sign(gradient)\n","        ############\n","        return perturbation\n","\n","\n","class PGD_attack:\n","    \"\"\"\n","        The PGD attack in warm-up task.\n","    \"\"\"\n","    def __init__(self, target_model: torchvision.models, epsilon: float, steps: int,\n","                 learning_rate: float = 1e-1):\n","        self.target_model = target_model\n","        self.epsilon = epsilon\n","        self.steps = steps\n","        self.learning_rate = learning_rate\n","\n","    def attack(self, test_image: torch.tensor, y_true: torch.tensor, is_targeted: bool = False,\n","               y_target: torch.tensor = None) -> torch.tensor:\n","\n","        perturbation = torch.zeros_like(test_image, requires_grad=True)\n","        opt = optim.SGD([perturbation], lr=self.learning_rate)\n","\n","        for t in range(self.steps):\n","            pred = self.target_model.predict(test_image + perturbation)\n","            if is_targeted:\n","                ############\n","                # TODO: implement the loss\n","                criterion = torch.nn.CrossEntropyLoss()\n","                loss = criterion(pred, y_target)\n","                ############\n","            else:\n","                ############\n","                # TODO: implement the loss\n","                criterion = torch.nn.CrossEntropyLoss()\n","                loss = -criterion(pred, y_true)\n","                ############\n","\n","            if t%10 == 0:\n","                print(\"PGD attack epoch %d: loss %s\"%(t,str(loss.item())))\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            ##########\n","            # TODO: update the perturbation\n","            ##########\n","            epsilon = torch.full(test_image.shape, self.epsilon)\n","            perturbation = torch.max(torch.min(perturbation.grad, epsilon), -epsilon).requires_grad_(True)\n","\n","        return perturbation"]},{"cell_type":"markdown","metadata":{"id":"uxxbhSnbYvxd"},"source":["### Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCAxk6MsY9UC"},"outputs":[],"source":["import time\n","from PIL import Image\n","\n","from utilities import *\n","from defense import standard_trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pHAs9NdZcIz"},"outputs":[],"source":["def compute_attack_grade_imagenet(attack_name, model, test_dir, eps=0.1, is_targeted=False, y_target=None, steps=10,\n","                                  learning_rate=0.1, num_pixel=None, defense_name=None):\n","    if attack_name == 'FSG':\n","        attacker = FSG_attack(model, eps)\n","    elif attack_name == 'PGD':\n","        attacker = PGD_attack(model, eps, steps, learning_rate)\n","\n","    else:\n","        raise ValueError('Please input the corret attack name: FSG, PGD, OP,adaptive')\n","\n","    if is_targeted:\n","        y_target = torch.LongTensor([y_target])\n","\n","        assert y_target is not None, ValueError('Please input the target label')\n","\n","    attack_grade = []\n","    attack_success = []\n","    start_time = time.time()\n","    for filename in os.listdir(test_dir)[:1]:\n","\n","        if filename.endswith(\".JPEG\"):\n","            # convert the name of the label to the number\n","            y_true = filename.split('_')[0]\n","            y_true_tensor = load_label_tensor(y_true)\n","\n","            # read the image and pre-processing the data\n","            test_image = Image.open(test_dir + filename)\n","            target_image_tensor = preprocess_features(test_image)[None, :, :, :]\n","\n","            # generate the pertubation\n","            delta = attacker.attack(target_image_tensor, y_true_tensor, is_targeted=is_targeted, y_target=y_target)\n","\n","            # generate the adv examples based on the pertubation\n","            adv_example = get_adv_example(target_image_tensor, delta, attack_name)\n","\n","            # compute the prediction based on the clean images and adversarial examples\n","            pred_clean = model.predict(target_image_tensor)\n","            pred_adv = model.predict(adv_example)\n","\n","            # compute the score of the attack\n","            grade, success = get_attack_score(y_true_tensor, pred_clean, pred_adv, is_targeted=is_targeted,\n","                                              y_target=y_target)\n","            if grade == -1 and success == -1:\n","                continue\n","            attack_grade.append(grade)\n","            attack_success.append(success)\n","\n","    print('----------results-------------')\n","    print(\"[%s attack against %s model] \\nattacking %d images using %.3f seconds\" % (\n","    attack_name, defense_name, len(attack_grade), time.time() - start_time))\n","    print(\"grade %.2f, success rate: %.2f\" % (np.array(attack_grade).mean(), np.array(attack_success).mean()))\n","\n","    return np.array(attack_grade).mean(), np.array(attack_grade).var()\n","\n","def get_attack_score(y_true: torch.tensor, pred_clean: torch.tensor, pred_adv: torch.tensor, weight: float = 0.5,\n","                     is_targeted: bool = False, y_target: torch.Tensor = None):\n","    assert pred_clean.argmax().item() == y_true.item(), ValueError(\"this image is not valid\")\n","\n","    if is_targeted:\n","        confid_clean = get_confidence(pred_clean, y_target.item())\n","        confid_adv = get_confidence(pred_adv, y_target.item())\n","        return weight * int(pred_adv.argmax().item() == y_target.item()) + (1 - weight) * (\n","                    confid_adv - confid_clean), int(pred_adv.argmax().item() == y_target.item())\n","    else:\n","        confid_clean = get_confidence(pred_clean, y_true.item())\n","        confid_adv = get_confidence(pred_adv, y_true.item())\n","\n","        return weight * int(pred_adv.argmax().item() != y_true.item()) + (1 - weight) * (\n","                    confid_clean - confid_adv), int(pred_adv.argmax().item() != y_true.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1681v7SOeYpb"},"outputs":[],"source":["class Randomization_Defense:\n","    def __init__(self, model, resize_bound):\n","        self.model = model\n","        self.resize_bound = resize_bound\n","\n","    def predict(self, test_image):\n","        normalize = transforms.Compose([\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","        return self.model(randomization_input(normalize(test_image), self.resize_bound))"]},{"cell_type":"markdown","metadata":{"id":"UdRNu1LxcAGI"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJKv9Z5baBzD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693592890853,"user_tz":-480,"elapsed":34567,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"1b52ebe9-638e-4b3d-b62d-8c0dda9ce361"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:01<00:00, 81.0MB/s]\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["PGD attack epoch 0: loss -0.068153016269207\n","PGD attack epoch 10: loss -0.007505314890295267\n","PGD attack epoch 20: loss -0.03793869912624359\n","PGD attack epoch 30: loss -0.03344587981700897\n","PGD attack epoch 40: loss -0.0394243448972702\n","----------results-------------\n","[PGD attack against randomization defense model] \n","attacking 1 images using 31.728 seconds\n","grade -0.01, success rate: 0.00\n"]}],"source":["pretrained_model = load_model()\n","target_model = Randomization_Defense(pretrained_model, 256)\n","defense_name = 'randomization defense'\n","\n","grade_mean, grade_variance = compute_attack_grade_imagenet(\"PGD\", target_model, \"test_image/\", eps=0.01, is_targeted=False, y_target=None, steps=50, learning_rate=0.02, defense_name=defense_name)"]},{"cell_type":"code","source":["grade_mean, grade_variance = compute_attack_grade_imagenet(\"PGD\", target_model, \"test_image/\", eps=0.01, is_targeted=True, y_target=25, steps=50, learning_rate=0.02, defense_name=defense_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYb9FRjy_y97","executionInfo":{"status":"ok","timestamp":1693592919736,"user_tz":-480,"elapsed":28891,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"46c5cfb6-3f1e-4ed6-d495-30fae9ff2469"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PGD attack epoch 0: loss 16.642498016357422\n","PGD attack epoch 10: loss 21.59040641784668\n","PGD attack epoch 20: loss 22.720443725585938\n","PGD attack epoch 30: loss 21.709941864013672\n","PGD attack epoch 40: loss 24.854631423950195\n","----------results-------------\n","[PGD attack against randomization defense model] \n","attacking 1 images using 29.136 seconds\n","grade -0.00, success rate: 0.00\n"]}]}],"metadata":{"colab":{"collapsed_sections":["U8tKsxW5oYTj","BK-LWx5SYZVk","PQJdCJDBZpcc","uxxbhSnbYvxd"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}