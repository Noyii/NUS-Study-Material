{"cells":[{"cell_type":"markdown","metadata":{"id":"GH1iAczDVRjJ"},"source":["# Task 3: Adaptive Attack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlLOrDdOAwuK"},"outputs":[],"source":["import pickle\n","import os\n","from torch import optim\n","import torch\n","import torchvision\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"aw9SZrTxoiOm"},"source":["### If you are using Google Colab, you need to upload this notebook and the codebase to your Google Drive. Then you need to mount your Google Drive in Colab and set your working directory. If you are running on your local machine, you can ignore the following line."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17760,"status":"ok","timestamp":1694159766861,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"},"user_tz":-480},"id":"WREld4LanEkm","outputId":"24d64245-942c-4eb2-936d-b218268a308d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWxeNJwv6kW9"},"outputs":[],"source":["root_dir = \"/content/drive/My Drive/\"\n","project_dir = \"Assignment1_code\" # Change to your path\n","os.chdir(root_dir + project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1694159767422,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"},"user_tz":-480},"id":"2FDukDiM7q7E","outputId":"29b6b9a9-a7fd-49b0-923b-64f1da670c44"},"outputs":[{"output_type":"stream","name":"stdout","text":["CS5562_Assignment_1_Task_1.ipynb    defense.py\t\t       __pycache__\n","CS5562_Assignment_1_Task_2.ipynb    environment.yml\t       results\n","CS5562_Assignment_1_Task_3.ipynb    imagenet_class_index.json  test_image\n","CS5562_Assignment_1_Task_4.ipynb    JSMA\t\t       utilities.py\n","CS5562_Assignment_1_Task_5.ipynb    MNIST\n","CS5562_Assignment_1_Warm_ups.ipynb  model.py\n"]}],"source":["# Make sure the path is correct\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"HVjiVuw9cqWU"},"source":["## Implement the Attack Algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSIOGqOFVUXb"},"outputs":[],"source":["from tqdm import tqdm\n","\n","class adaptive_attack:\n","    \"\"\"\n","    The adaptive attack in Task 3 to break the defense model in Task 2.\n","    \"\"\"\n","\n","    def __init__(self, target_model: torchvision.models, epsilon: float,steps:int,learning_rate:float):\n","        self.target_model = target_model\n","        self.epsilon = epsilon\n","        self.learning_rate = learning_rate\n","        self.steps = steps\n","\n","    def attack(self, test_image: torch.tensor, y_true: torch.tensor, is_targeted: bool = False,\n","               y_target: torch.tensor = None) -> torch.tensor:\n","        ##########\n","        # TODO: implement your attack\n","        def FGSM(input_image):\n","          \"\"\"\n","          The FSGM attack in warm-up task.\n","          \"\"\"\n","          perturbation = torch.zeros_like(input_image, requires_grad=True)\n","          pred = self.target_model.predict(input_image + perturbation)\n","          criterion = torch.nn.CrossEntropyLoss()\n","\n","          if is_targeted:\n","              loss = -criterion(pred, y_target)\n","          else:\n","              loss = criterion(pred, y_true)\n","\n","          loss.backward()\n","          return perturbation.grad\n","\n","        # Attack implementation for FGSM\n","        N = 100\n","        gradients = []\n","        for _ in tqdm(range(N)):\n","          gradients.append(FGSM(test_image))\n","\n","        # EOT\n","        perturbation = torch.sign(sum(gradients)/len(gradients)) * self.epsilon\n","\n","        ##########\n","        return perturbation"]},{"cell_type":"markdown","metadata":{"id":"3UIqRHXKc02y"},"source":["## Test your code"]},{"cell_type":"markdown","metadata":{"id":"z5jWh9HbfGte"},"source":["### Copy and paste your Task 2 algorithm here"]},{"cell_type":"code","source":["from torchvision import transforms\n","import torch\n","from scipy.stats import norm, binom_test\n","import numpy as np\n","from math import ceil\n","from statsmodels.stats.proportion import proportion_confint\n","import torch.nn as nn\n","import torchvision\n","from torch import optim"],"metadata":{"id":"XaNGc5W-QJb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMz5aN9KfK6A"},"outputs":[],"source":["def randomization_input(test_image, resize_bound):\n","    '''\n","    :param test_image: the test image which could be clean or adversarial. The size is [1, 3, 224,224]\n","    :return: randomized version of the test image. The size is [1, 3, resize_bound, resize_bound].\n","    Hints:\n","    1. Sample a integer number uniformly from [1,10]: np.random.randint(1,10, size=1)\n","    2. Pytorch provides transforms function for image transformations. You can call the transforms.Resize to resize your images (https://pytorch.org/vision/stable/transforms.html).\n","    >>> p = transforms.Compose([transforms.Resize(48)])\n","    >>> p(test_image)\n","    3. Pytorch provides torch.nn.functional.pad function to pad tensors.\n","    '''\n","\n","    PAD_VALUE = 0.5  # this is the pad value for the random padding step\n","    randomized_image = test_image\n","    ################\n","    # TODO: implement randomized resizing and randomized padding.\n","    rand_W, rand_H = np.random.randint(low=224, high=resize_bound, size=2)\n","\n","    ## Resizing between [224, resize_bound) for least performance drop in clean images.\n","    resized_image = transforms.Resize(size=(rand_H, rand_W))(randomized_image)\n","\n","    ## Padding - (padding_left, padding_right, padding_top, padding_bottom)\n","    leftover_W, leftover_H = (resize_bound - rand_W), (resize_bound - rand_H)\n","    prob_w, prob_h = np.random.randint(0, 11, size=2)\n","\n","    left = int(leftover_W * prob_w/10)\n","    right = leftover_W - left\n","    top = int(leftover_H * prob_h/10)\n","    bottom = leftover_H - top\n","\n","    pad = (left, right, top, bottom)\n","    randomized_image = nn.functional.pad(resized_image, pad, \"constant\", PAD_VALUE)\n","    assert randomized_image.shape == torch.Size([1, 3, resize_bound, resize_bound]), ValueError('Shape does not match')\n","\n","    ################\n","    return randomized_image"]},{"cell_type":"markdown","metadata":{"id":"uxxbhSnbYvxd"},"source":["### Helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCAxk6MsY9UC"},"outputs":[],"source":["import time\n","from PIL import Image\n","\n","from utilities import *\n","from defense import standard_trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pHAs9NdZcIz"},"outputs":[],"source":["def compute_attack_grade_imagenet(model, test_dir, eps=0.1, is_targeted=False, y_target=None, steps=10,\n","                                  learning_rate=0.1, num_pixel=None, defense_name=None):\n","    attacker = adaptive_attack(model, eps, steps, learning_rate)\n","\n","    if is_targeted:\n","        y_target = torch.LongTensor([y_target])\n","\n","        assert y_target is not None, ValueError('Please input the target label')\n","\n","    attack_grade = []\n","    attack_success = []\n","    start_time = time.time()\n","    for filename in os.listdir(test_dir)[:1]:\n","\n","        if filename.endswith(\".JPEG\"):\n","            # convert the name of the label to the number\n","            y_true = filename.split('_')[0]\n","            y_true_tensor = load_label_tensor(y_true)\n","\n","            # read the image and pre-processing the data\n","            test_image = Image.open(test_dir + filename)\n","            target_image_tensor = preprocess_features(test_image)[None, :, :, :]\n","\n","            # generate the pertubation\n","            delta = attacker.attack(target_image_tensor, y_true_tensor, is_targeted=is_targeted, y_target=y_target)\n","\n","            # generate the adv examples based on the pertubation\n","            adv_example = get_adv_example(target_image_tensor, delta, \"adaptive\")\n","\n","            # compute the prediction based on the clean images and adversarial examples\n","            pred_clean = model.predict(target_image_tensor)\n","            pred_adv = model.predict(adv_example)\n","\n","            # compute the score of the attack\n","            grade, success = get_attack_score(y_true_tensor, pred_clean, pred_adv, is_targeted=is_targeted,\n","                                              y_target=y_target)\n","            if grade == -1 and success == -1:\n","                continue\n","            attack_grade.append(grade)\n","            attack_success.append(success)\n","\n","    print('----------results-------------')\n","    print(\"[%s attack against %s model] \\nattacking %d images using %.3f seconds\" % (\n","    \"adaptive\", defense_name, len(attack_grade), time.time() - start_time))\n","    print(\"grade %.2f, success rate: %.2f\" % (np.array(attack_grade).mean(), np.array(attack_success).mean()))\n","\n","    return np.array(attack_grade).mean(), np.array(attack_grade).var()\n","\n","def get_attack_score(y_true: torch.tensor, pred_clean: torch.tensor, pred_adv: torch.tensor, weight: float = 0.5,\n","                     is_targeted: bool = False, y_target: torch.Tensor = None):\n","    # assert pred_clean.argmax().item() == y_true.item(), ValueError(\"this image is not valid\")\n","    if pred_clean.argmax().item() != y_true.item():\n","        return -1, -1\n","\n","    if is_targeted:\n","        confid_clean = get_confidence(pred_clean, y_target.item())\n","        confid_adv = get_confidence(pred_adv, y_target.item())\n","        return weight * int(pred_adv.argmax().item() == y_target.item()) + (1 - weight) * (\n","                    confid_adv - confid_clean), int(pred_adv.argmax().item() == y_target.item())\n","    else:\n","        confid_clean = get_confidence(pred_clean, y_true.item())\n","        confid_adv = get_confidence(pred_adv, y_true.item())\n","\n","        return weight * int(pred_adv.argmax().item() != y_true.item()) + (1 - weight) * (\n","                    confid_clean - confid_adv), int(pred_adv.argmax().item() != y_true.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuwBQ_30eoXI"},"outputs":[],"source":["class Randomization_Defense:\n","    def __init__(self, model, resize_bound):\n","        self.model = model\n","        self.resize_bound = resize_bound\n","\n","    def predict(self, test_image):\n","        normalize = transforms.Compose([\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","        return self.model(randomization_input(normalize(test_image), self.resize_bound))"]},{"cell_type":"markdown","metadata":{"id":"UdRNu1LxcAGI"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJKv9Z5baBzD","executionInfo":{"status":"ok","timestamp":1693987208914,"user_tz":-480,"elapsed":60241,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"cdd66daa-781f-464d-c4a4-4211c70128d0"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:59<00:00,  1.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["----------results-------------\n","[adaptive attack against randomization defense model] \n","attacking 1 images using 59.834 seconds\n","grade 0.98, success rate: 1.00\n"]}],"source":["pretrained_model = load_model()\n","target_model = Randomization_Defense(pretrained_model, 256)\n","defense_name = 'randomization defense'\n","grade_mean, grade_variance = compute_attack_grade_imagenet(target_model, \"test_image/\", eps=0.01, is_targeted=False, y_target=None, defense_name=defense_name)"]},{"cell_type":"markdown","metadata":{"id":"ipkRgKvZtcaR"},"source":["# Report"]},{"cell_type":"markdown","metadata":{"id":"ofagzOTmteRS"},"source":["Please describe your attack strategy and write down how you overcomed the difficulties you faced if any."]},{"cell_type":"markdown","metadata":{"id":"x5Gw6swKtxUh"},"source":["Your Response:\n","\n","## Attack Strategy\n","\n","My core attack algorithm is FGSM. However, I added a slight modification to incorporate Expectation of Transformation (EOT) into my attack strategy.\n","\n","- Since we know that the input image is transformed before getting fed into the classifier, I try to guess the gradient of the loss wrt the perturbation by sampling N randomly transformed images and calculating the expectation of their loss gradients.\n","\n","- The idea is that the expectation of loss gradients of N samples would be a close approximation to the true gradient of the input image.\n","\n","- Moreover, I implemented an attack algorithm like FGSM over PGD since single-step attacks are faster to implement (especially on a large N) and have greater generalization.\n","\n","\n","## Observed Results\n","\n","- For untargetted attacks, My implemented works with:\n","```\n","N = 100\n","grade 0.99\n","success rate: 1.00\n","```\n","\n","I attribute this to the fact that the loss landscape of a neural network is highly complex and the decision boundaries of each of the 1000 classes are greatly convoluted. Therefore, in order to misclassify towards any other 999 classes, it is easier to approximate the gradient direction from a relatively small subset of samples.\n","\n","- For a targetted attack, my implementation fails to attack even with\n","```\n","N = 1000\n","target_class = 100\n","true_pred = 701\n","```\n","I attribute this to the idea that:\n","  - either the no. of drawn samples are not sufficient to get a close approximation of the true gradients which can be circumvented by drawing large samples, e.g. `N=1Million`, but this comes with a huge computation cost, OR,\n","  - The gradients are approximately correct but the decision boundary of the targetted class does not lie within the ϵ-ball of the input data. Perhaps, it might be successful to target another class with a closer decision boundary.\n","\n","## Difficulties faced\n","\n","- I was initially under the false impression that transformations (padding and resizing specifically) are non-differentiable. Hence, I was trying to compute gradients in some weird way, and it ended up not working correctly (was having size issues: `224` vs `resize_bound`).\n","\n","- I overcame this difficulty by reading the PyTorch documentation on transformations correctly (LOL)."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["aw9SZrTxoiOm","z5jWh9HbfGte","uxxbhSnbYvxd"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}