{"cells":[{"cell_type":"markdown","metadata":{"id":"48JBRWUfTS58"},"source":["# Task 1: JSMA Attack"]},{"cell_type":"markdown","metadata":{"id":"wrf2BSSe6INY"},"source":["## Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lgj7hu7yTLcX"},"outputs":[],"source":["import pickle\n","import tensorflow as tf\n","import os\n","from torch import optim\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"ZV90iKg7oeFR"},"source":["### If you are using Google Colab, you need to upload this notebook and the codebase to your Google Drive. Then you need to mount your Google Drive in Colab and set your working directory. If you are running on your local machine, you can ignore the following line."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WREld4LanEkm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693814983838,"user_tz":-480,"elapsed":2208,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"794d87b3-7a6c-4ccc-8337-cbdc33262255"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWxeNJwv6kW9"},"outputs":[],"source":["root_dir = \"/content/drive/My Drive/\"\n","project_dir = \"Assignment1_code\" # Change to your path\n","os.chdir(root_dir + project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FDukDiM7q7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693814983839,"user_tz":-480,"elapsed":7,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"4937f7b9-3040-41a3-9fdb-61b4d0e8db26"},"outputs":[{"output_type":"stream","name":"stdout","text":["CS5562_Assignment_1_Task_1.ipynb    imagenet_class_index.json\n","CS5562_Assignment_1_Task_2.ipynb    JSMA\n","CS5562_Assignment_1_Task_3.ipynb    model.py\n","CS5562_Assignment_1_Task_4.ipynb    __pycache__\n","CS5562_Assignment_1_Task_5.ipynb    results\n","CS5562_Assignment_1_Warm_ups.ipynb  test_image\n","defense.py\t\t\t    utilities.py\n","environment.yml\n"]}],"source":["# Make sure the path is correct\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"UD8JjXN29Icg"},"source":["### Importing helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6t-dMxRz7nhN"},"outputs":[],"source":["from JSMA.pixelmap import AlgorithmEnum, Homography\n","from JSMA.utilities import generate_hull_mask, plot_and_save_graph, SDC_data\n","from utilities import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzG5IOMTTWyX"},"outputs":[],"source":["def JSMA_image(result_dir, attack_dir, is_mask=True, pixelmap=None, max_iters=50, debug_flag=False):\n","    # Credit to Jonathan Cheng for sharing the code.\n","    MODELS_DIR = 'JSMA/models'\n","    MODEL_NAME = 'sdc-50epochs-shuffled'\n","    IMAGE_FILE = None\n","    IMAGE_FOLDER = None\n","    RESULTS_DIR = None\n","    MAX_ITERATIONS = max_iters\n","\n","    MODEL_PATH = os.path.join(MODELS_DIR, MODEL_NAME)\n","\n","    # Path to attack folder\n","    IMAGE_FILE = os.path.join(attack_dir, 'attack.csv')\n","    IMAGE_FOLDER = attack_dir\n","    print('Using attack target images from: ' + IMAGE_FOLDER)\n","    print('Using attack target labels from: ' + IMAGE_FILE)\n","\n","    RESULTS_DIR = os.path.join('results/', result_dir)\n","    if not os.path.isdir(RESULTS_DIR):\n","        os.makedirs(RESULTS_DIR)\n","\n","    if pixelmap is not None:\n","        # Set the enum for which algorithm to use\n","        if pixelmap not in ['homography']:\n","            raise ValueError('pixelmap is one of: \"homography\"')\n","        if pixelmap == 'homography':\n","            PIXELMAP_ALGO = AlgorithmEnum.HOMOGRAPHY\n","    else:\n","        PIXELMAP_ALGO = None\n","\n","    data = SDC_data(IMAGE_FILE, IMAGE_FOLDER)\n","    model = tf.keras.models.load_model(MODEL_PATH)\n","\n","    attack = JSMARegressionAttack(model,\n","                                  RESULTS_DIR,\n","                                  is_mask=True,\n","                                  pixelmap_algo=PIXELMAP_ALGO,\n","                                  max_iters=MAX_ITERATIONS,\n","                                  )\n","\n","    input_imgs = data.input_data\n","    adv_imgs = attack.attack(data)"]},{"cell_type":"markdown","metadata":{"id":"pkPrPU2l55f-"},"source":["## Complete the attack algorithm by filling in the TODO blocks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JcQuG9un6B6S"},"outputs":[],"source":["class JSMARegressionAttack:\n","    \"\"\"\n","    The JSMA attack. Credit to Jonathan Cheng for sharing the code.\n","    Returns adversarial examples for the supplied model.\n","    model: The model on which we perform the attack on.\n","    max_iters: The maximum number of iterations.\n","      Corresponds to the number of (pixel, colour) coordinates to perturb\n","    pixelmap_algo: Which mapping algorithm to use for the pixel mapping (don't map if None)\n","    clip_max: Maximum pixel value (default 1.0).\n","    clip_min: Minimum pixel value (default 0.0).\n","    increase: Direction of pixel values to perturb towards\n","      Does NOT affect the adversarial steering angles\n","    is_mask: Flag; Do we constraint the pertubation to a speciific region?\n","    \"\"\"\n","\n","    def __init__(self, model, resultsdir, max_iters=50, pixelmap_algo=None, clip_max=1.0, clip_min=0.0,\n","                 increase=True, is_mask=True):\n","        self.model = model\n","        self.resultsdir = resultsdir\n","        self.max_iters = max_iters\n","        self.pixelmap_algo = pixelmap_algo\n","        self.clip_max = clip_max\n","        self.clip_min = clip_min\n","        self.increase = increase\n","        self.is_mask = is_mask\n","        self.adv_preds = []\n","        self.adv_diffs = []\n","\n","    def diff_avg(self, adv_diffs):\n","        return sum(adv_diffs) / len(adv_diffs)\n","\n","    def seq_diff_avg(self, adv_diffs):\n","        adv_diffs_copy = adv_diffs.copy()\n","        seq_diffs = list(map(lambda pair: abs(pair[0] - pair[1]),\n","                             zip(adv_diffs_copy[1:], adv_diffs_copy[:len(adv_diffs_copy) - 1])))\n","        return sum(seq_diffs) / len(seq_diffs)\n","\n","    def visualize_attack(self, batch_size, deltas, imgs):\n","        adv_preds = tf.squeeze(tf.stack(self.adv_preds, axis=1)).numpy()\n","        with open(os.path.join(self.resultsdir, 'preds.pkl'), 'wb') as f:\n","            pickle.dump(adv_preds.tolist(), f)\n","        plot_and_save_graph(adv_preds,\n","                            title='Predictions_Over_Rounds',\n","                            xlabel='Rounds',\n","                            ylabel='Adversarial Predictions',\n","                            savedir=self.resultsdir)\n","        adv_diffs = tf.squeeze(tf.stack(self.adv_diffs, axis=1)).numpy()\n","        with open(os.path.join(self.resultsdir, 'adv_diffs.pkl'), 'wb') as f:\n","            pickle.dump(adv_diffs.tolist(), f)\n","        plot_and_save_graph(adv_diffs,\n","                            title='Predictions_Difference_Over_Rounds',\n","                            xlabel='Rounds',\n","                            ylabel='Adversarial Predictions (Difference)',\n","                            savedir=self.resultsdir)\n","        adv_imgs = imgs + deltas\n","        # Save images of the deltas\n","        for i in range(batch_size):\n","            fig = plt.figure(frameon=False)\n","            ax = plt.Axes(fig, [0., 0., 1., 1.])\n","            ax.set_axis_off()\n","            fig.add_axes(ax)\n","            ax.imshow(tf.cast(deltas[i] != 0.0, tf.float32), interpolation='none')\n","            fig.savefig(os.path.join(self.resultsdir, 'delta' + str(i) + '.png'), dpi=250)\n","            plt.close(fig)\n","        # Save images of the perturbed target\n","        for i in range(batch_size):\n","            fig = plt.figure(frameon=False)\n","            ax = plt.Axes(fig, [0., 0., 1., 1.])\n","            ax.set_axis_off()\n","            fig.add_axes(ax)\n","            ax.imshow(adv_imgs[i], interpolation='none')\n","            fig.savefig(os.path.join(self.resultsdir, 'adv_image' + str(i) + '.png'), dpi=250)\n","            plt.close(fig)\n","        final_abs_adv_diffs = list(map(lambda diff: abs(diff), tf.squeeze(adv_diffs[:, -1:]).numpy().tolist()))\n","        print('Average difference:              ', self.diff_avg(final_abs_adv_diffs))\n","        print('Average sequantial difference:   ', self.seq_diff_avg(final_abs_adv_diffs))\n","        score = open(os.path.join(self.resultsdir, \"score\"), \"w\")\n","        score.write('Average difference:              ' + str(self.diff_avg(final_abs_adv_diffs)) + '\\n')\n","        score.write('Average sequantial difference:   ' + str(self.seq_diff_avg(final_abs_adv_diffs)) + '\\n')\n","        score.close()\n","        return adv_imgs\n","\n","    def attack(self, data):\n","        # Sanity checks on data\n","        imgs, targets = data.input_data, data.output_data\n","        assert (len(imgs) == len(targets))\n","        if self.is_mask:\n","            sequence_of_list_of_corners = data.sequence_of_list_of_corners\n","            assert (len(sequence_of_list_of_corners) == len(imgs))\n","\n","        print('Number of attack targets:    ', len(imgs))\n","        if self.is_mask:\n","            if self.pixelmap_algo:\n","                deltas = self.attack_pixelmap(data)\n","            else:\n","                deltas = self.attack_batch(data)\n","            adv_imgs = self.visualize_attack(len(imgs), deltas, imgs)\n","            return adv_imgs\n","        else:\n","            raise NotImplementedError('Not required for this assignment')\n","\n","    def attack_batch(self, data):\n","        \"\"\"\n","        Run the attack on a batch of images and labels.\n","        \"\"\"\n","        imgs = data.input_data\n","        labs = data.output_data\n","        batch_size = len(imgs)\n","        sequence_of_list_of_corners = data.sequence_of_list_of_corners\n","\n","        x = tf.cast(tf.constant(imgs), tf.float32)\n","        y_true = tf.expand_dims(tf.cast(tf.constant(labs), tf.float32), axis=1)\n","\n","        # Compute our initial search domain.  We optimize the initial search domain\n","        # by removing all features that are already at their maximum values (if\n","        # increasing input features---otherwise, at their minimum value).\n","        if self.increase:\n","            search_domains = tf.Variable(tf.reshape(tf.equal(tf.cast(x < self.clip_max, tf.float32), 1.0), x.shape))\n","        else:\n","            search_domains = tf.Variable(tf.reshape(tf.equal(tf.cast(x > self.clip_min, tf.float32), 1.0), x.shape))\n","\n","        # Manually calculate the allowed perturbation area\n","        # search_domains: A boolean mask to apply over the input images\n","        # search_domain_indices: A list (tensor) of vertices of the input images that are allowed to be perturbed\n","        if self.is_mask:\n","            for i in range(batch_size):\n","                list_of_corners = sequence_of_list_of_corners[i]\n","                pertubation_mask = generate_hull_mask(x.shape[1:3], np.array(list_of_corners))\n","                search_domains = search_domains[i].assign(\n","                    tf.math.logical_and(search_domains[i], tf.expand_dims(pertubation_mask, axis=2)))\n","        sparse_search_domains = tf.sparse.from_dense(tf.cast(tf.where(search_domains, x=1., y=0.), dtype=tf.float32))\n","        search_domain_indices = sparse_search_domains.indices\n","\n","        # Create the variable tensor to calculate the jacobian\n","        deltas = tf.Variable(initial_value=tf.zeros_like(x),\n","                             shape=x.shape,\n","                             name='deltas',\n","                             dtype=tf.float32)\n","\n","        original_pred = self.model.predict(x)\n","\n","        # List of adversarial predictions and difference against original predictions in each iteration\n","        self.adv_preds.append(original_pred)\n","        self.adv_diffs.append(tf.zeros(shape=[batch_size, 1]))\n","\n","        for i in range(self.max_iters):\n","            print('Rounds of perturbation:  ', i + 1)\n","\n","            # Construct the computation graph to calculate the gradients (Jacobians)\n","            with tf.GradientTape(persistent=False, watch_accessed_variables=False) as tape:\n","                tape.watch(deltas)\n","                y = self.model(x + deltas)\n","                mseloss = (y - y_true) * (y - y_true) * 1 / 2\n","\n","            # Will have shape: (batch size, <image.shape>)\n","            jacs = tf.squeeze(tape.batch_jacobian(mseloss, deltas), axis=1)\n","\n","            to_add = tf.Variable(tf.zeros_like(deltas, dtype=tf.float32))\n","\n","            # TODO\n","            # 1) Use `search_domains` and/or `search_domain_indices` to find the next pixel to update\n","            # 2) Assign `to_add`, and keep track of pixels updated so you don't pick it again in the next iteration\n","\n","            # Loop through every image\n","            for i in range(batch_size):\n","              # Get available pixels and their jacobians to perturb\n","              search_indices = tf.sparse.from_dense(tf.cast(tf.where(search_domains[i], x=1., y=0.), dtype=tf.float32)).indices\n","              allowed_jacs = tf.boolean_mask(jacs[i], search_domains[i])\n","\n","              # Get pixel with highest jacobian in magnitude since changing that pixel will cause max harm .\n","              # High jacobian means high sensitivity to input pixel values\n","              highest_jac_ind = tf.math.argmax(tf.math.abs(allowed_jacs))\n","              a, b, c = tf.gather(search_indices, highest_jac_ind)\n","\n","              # Set value of pixel to mag(1)\n","              # Assigning highest perturbation budget for maximum damage in each direction\n","              if allowed_jacs[highest_jac_ind] < 0:\n","                to_add[i, a, b, c].assign(-1)\n","              else:\n","                to_add[i, a, b, c].assign(1)\n","\n","              # Remove pixel from available pixel set\n","              search_domains[i, a, b].assign(False)\n","\n","            # End of TODO\n","\n","            # Update deltas\n","            deltas.assign(deltas + to_add)\n","            adv_pred = self.model.predict(x + deltas)\n","            # Record the effectiveness of perturbation at this iteration\n","            self.adv_preds.append(adv_pred)\n","            self.adv_diffs.append(original_pred - adv_pred)\n","        return deltas\n","\n","    def attack_pixelmap(self, data):\n","        \"\"\"\n","        Run the attack on a batch of images and labels.\n","        Do so by pertubring pixels in parallel, mapping pixels using some specified algorithm\n","        \"\"\"\n","        imgs = data.input_data\n","        labs = data.output_data\n","        batch_size = len(imgs)\n","        sequence_of_list_of_corners = data.sequence_of_list_of_corners\n","\n","        x = tf.cast(tf.constant(imgs), tf.float32)\n","        y_true = tf.expand_dims(tf.cast(tf.constant(labs), tf.float32), axis=1)\n","\n","        if self.pixelmap_algo == AlgorithmEnum.HOMOGRAPHY:\n","            for list_of_corners in sequence_of_list_of_corners:\n","                assert (not list_of_corners is None)\n","            pixelmap = Homography(sequence_of_list_of_corners, x.shape[1:3])\n","\n","        # Create the variable tensor to calculate the jacobian\n","        deltas = tf.Variable(initial_value=tf.zeros_like(x),\n","                             shape=x.shape,\n","                             name='deltas',\n","                             dtype=tf.float32)\n","\n","        original_pred = self.model.predict(x)\n","\n","        # List of adversarial predictions and difference against original predictions in each iteration\n","        self.adv_preds.append(original_pred)\n","        self.adv_diffs.append(tf.zeros(shape=[batch_size, 1]))\n","\n","        for i in range(self.max_iters):\n","            # If there are no more vertice strings left to perturbed, end early\n","            if pixelmap.get_length_of_vertice_strings() == 0:\n","                break\n","\n","            # Construct the computation graph to calculate the gradients (Jacobians)\n","            with tf.GradientTape(persistent=False, watch_accessed_variables=False) as tape:\n","                tape.watch(deltas)\n","                y = self.model(x + deltas)\n","                mseloss = (y - y_true) * (y - y_true) * 1 / 2\n","\n","            # Will have shape: (batch size, <image.shape>)\n","            jacs = tf.squeeze(tape.batch_jacobian(mseloss, deltas), axis=1)\n","\n","            to_add = tf.Variable(tf.zeros_like(deltas, dtype=tf.float32))\n","\n","            list_of_vertice_strings = pixelmap.get_list_of_vertice_strings()\n","\n","            # TODO\n","            # 1) Use `list_of_vertice_strings` to find the best string of vertices to update in parallel\n","            # 2) Assign `to_add`, and update `pixelmap` by calling `delete_vertice_string()` so you don't use the same vertice string twice\n","\n","            # get 2100 * 20 jacobian magnitudes\n","            all_jacs = []\n","            for indices in list_of_vertice_strings:\n","              selected_jacs = tf.gather_nd(jacs, indices)\n","              all_jacs.append(selected_jacs)\n","\n","            all_jacs = tf.convert_to_tensor(all_jacs)\n","\n","            # get average jacobian of each frame\n","            average_jac = tf.reduce_mean(all_jacs, 0)\n","\n","            # count how many frames in each vertice string have jacobian higher than frame-avg\n","            jacs_higher_than_avg_count = tf.reduce_sum(tf.cast(tf.greater(all_jacs, average_jac), tf.float32), axis=1)\n","\n","            # get vertice string with highest count\n","            chosen_index = tf.argmax(jacs_higher_than_avg_count)\n","            chosen_vertice_string = list_of_vertice_strings[chosen_index]\n","\n","            # update to_add for 20 frames\n","            for b, p1, p2, c in chosen_vertice_string:\n","              to_add[b, p1, p2, c].assign(1)\n","\n","            # remove vertice string from available vertice strings\n","            pixelmap.delete_vertice_string(chosen_index)\n","\n","            # End of TODO\n","\n","            # Update deltas\n","            deltas = deltas.assign(deltas + to_add)\n","\n","            adv_pred = self.model.predict(x + deltas)\n","            # Record the effectiveness of perturbation at this iteration\n","            self.adv_preds.append(adv_pred)\n","            self.adv_diffs.append(original_pred - adv_pred)\n","\n","        return deltas\n"]},{"cell_type":"markdown","metadata":{"id":"bjLMJoXh-1Qt"},"source":["# Test your code"]},{"cell_type":"markdown","metadata":{"id":"MMZ45mjX5EfC"},"source":["Below is two code snippets to test your algorithm runs. You should observe that your attack algorithm results in non-zero differences."]},{"cell_type":"markdown","source":["### Objective 1"],"metadata":{"id":"srB8Uak7jjY3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulUmTwQ_-3Tk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693813896622,"user_tz":-480,"elapsed":52986,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"9b1552b9-d777-4401-d4e0-2579adc911df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using attack target images from: JSMA/attack_targets/attack_left\n","Using attack target labels from: JSMA/attack_targets/attack_left/attack.csv\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"]},{"output_type":"stream","name":"stdout","text":["Number of attack targets:     20\n","1/1 [==============================] - 0s 122ms/step\n","Rounds of perturbation:   1\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   2\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   3\n","1/1 [==============================] - 0s 20ms/step\n","Rounds of perturbation:   4\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   5\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   6\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   7\n","1/1 [==============================] - 0s 29ms/step\n","Rounds of perturbation:   8\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   9\n","1/1 [==============================] - 0s 25ms/step\n","Rounds of perturbation:   10\n","1/1 [==============================] - 0s 24ms/step\n","Rounds of perturbation:   11\n","1/1 [==============================] - 0s 22ms/step\n","Rounds of perturbation:   12\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   13\n","1/1 [==============================] - 0s 22ms/step\n","Rounds of perturbation:   14\n","1/1 [==============================] - 0s 30ms/step\n","Rounds of perturbation:   15\n","1/1 [==============================] - 0s 37ms/step\n","Rounds of perturbation:   16\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   17\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   18\n","1/1 [==============================] - 0s 20ms/step\n","Rounds of perturbation:   19\n","1/1 [==============================] - 0s 22ms/step\n","Rounds of perturbation:   20\n","1/1 [==============================] - 0s 30ms/step\n","Rounds of perturbation:   21\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   22\n","1/1 [==============================] - 0s 25ms/step\n","Rounds of perturbation:   23\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   24\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   25\n","1/1 [==============================] - 0s 24ms/step\n","Rounds of perturbation:   26\n","1/1 [==============================] - 0s 24ms/step\n","Rounds of perturbation:   27\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   28\n","1/1 [==============================] - 0s 33ms/step\n","Rounds of perturbation:   29\n","1/1 [==============================] - 0s 28ms/step\n","Rounds of perturbation:   30\n","1/1 [==============================] - 0s 32ms/step\n","Rounds of perturbation:   31\n","1/1 [==============================] - 0s 31ms/step\n","Rounds of perturbation:   32\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   33\n","1/1 [==============================] - 0s 22ms/step\n","Rounds of perturbation:   34\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   35\n","1/1 [==============================] - 0s 24ms/step\n","Rounds of perturbation:   36\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   37\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   38\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   39\n","1/1 [==============================] - 0s 23ms/step\n","Rounds of perturbation:   40\n","1/1 [==============================] - 0s 29ms/step\n","Rounds of perturbation:   41\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   42\n","1/1 [==============================] - 0s 20ms/step\n","Rounds of perturbation:   43\n","1/1 [==============================] - 0s 22ms/step\n","Rounds of perturbation:   44\n","1/1 [==============================] - 0s 39ms/step\n","Rounds of perturbation:   45\n","1/1 [==============================] - 0s 43ms/step\n","Rounds of perturbation:   46\n","1/1 [==============================] - 0s 35ms/step\n","Rounds of perturbation:   47\n","1/1 [==============================] - 0s 31ms/step\n","Rounds of perturbation:   48\n","1/1 [==============================] - 0s 21ms/step\n","Rounds of perturbation:   49\n","1/1 [==============================] - 0s 57ms/step\n","Rounds of perturbation:   50\n","1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["Average difference:               6.190826010704041\n","Average sequantial difference:    0.5791924627203691\n"]}],"source":["JSMA_image(result_dir=\"test1\", attack_dir=\"JSMA/attack_targets/attack_left\")"]},{"cell_type":"markdown","source":["### Objective 2"],"metadata":{"id":"1pt72_VOjnfk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7pntdu1_dvx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693815077908,"user_tz":-480,"elapsed":83859,"user":{"displayName":"Niharika Shrivastava","userId":"07199383378542377502"}},"outputId":"f7331d71-545a-4007-b91f-d46e637262f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using attack target images from: JSMA/attack_targets/attack_left\n","Using attack target labels from: JSMA/attack_targets/attack_left/attack.csv\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"]},{"output_type":"stream","name":"stdout","text":["Number of attack targets:     20\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 75ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 33ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["Average difference:               2.383523201942444\n","Average sequantial difference:    0.27321183054070725\n"]}],"source":["# This test takes longer to run in Colab.\n","JSMA_image(result_dir=\"test2\", attack_dir=\"JSMA/attack_targets/attack_left\", pixelmap=\"homography\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["wrf2BSSe6INY","ZV90iKg7oeFR","srB8Uak7jjY3"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}