{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GH1iAczDVRjJ"
   },
   "source": [
    "# Task 4: Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 11646,
     "status": "ok",
     "timestamp": 1694257846751,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "qlLOrDdOAwuK"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "from scipy.stats import norm, binom_test\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuSr1XwZoltM"
   },
   "source": [
    "### If you are using Google Colab, you need to upload this notebook and the codebase to your Google Drive. Then you need to mount your Google Drive in Colab and set your working directory. If you are running on your local machine, you can ignore the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17818,
     "status": "ok",
     "timestamp": 1694257864566,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "WREld4LanEkm",
    "outputId": "74661230-808b-4b13-995c-90c094f66aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1694257864567,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "rWxeNJwv6kW9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = \"/content/drive/My Drive/\"\n",
    "project_dir = \"Assignment1_code\" # Change to your path\n",
    "os.chdir(root_dir + project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1694257864567,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "2FDukDiM7q7E",
    "outputId": "5d6f263f-03ca-4c2e-88d1-e11d01502f10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS5562_Assignment_1_Task_1.ipynb    defense.py\t\t       __pycache__\n",
      "CS5562_Assignment_1_Task_2.ipynb    environment.yml\t       results\n",
      "CS5562_Assignment_1_Task_3.ipynb    imagenet_class_index.json  test_image\n",
      "CS5562_Assignment_1_Task_4.ipynb    JSMA\t\t       utilities.py\n",
      "CS5562_Assignment_1_Task_5.ipynb    MNIST\n",
      "CS5562_Assignment_1_Warm_ups.ipynb  model.py\n"
     ]
    }
   ],
   "source": [
    "# Make sure the path is correct\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVjiVuw9cqWU"
   },
   "source": [
    "## Implement the Robust Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1694263745544,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "YSIOGqOFVUXb"
   },
   "outputs": [],
   "source": [
    "def robust_trainer(loader, model, epsilon, opt=None):\n",
    "    total_loss, total_err = 0., 0.\n",
    "    for X, y in loader:\n",
    "        #################\n",
    "        # TODO: implement your robust training. Implement the loss and the prediction of the model.\n",
    "\n",
    "        sign = torch.sign(model.weight).type(torch.LongTensor)\n",
    "\n",
    "        ### Projected y ==> {-1, 1} in order to maintain consistency with the current experiment.\n",
    "        mapped_y = y\n",
    "        mapped_y[mapped_y == 0] = -1\n",
    "        mapped_y = mapped_y[:, None, None]\n",
    "\n",
    "        # Get best adversarial image for y ==> {-1, 1}\n",
    "        adv_X = torch.flatten(X, 2) - epsilon*torch.matmul(mapped_y, sign)\n",
    "        pred = model(adv_X).squeeze()\n",
    "\n",
    "        # Outer optimization\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = criterion(pred, y.float())\n",
    "\n",
    "        #################\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        total_err += ((pred > 0) * (y == 0) + (pred < 0) * (y == 1)).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "251xII65ClJQ"
   },
   "source": [
    "## Test your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxxbhSnbYvxd"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4290,
     "status": "ok",
     "timestamp": 1694257868854,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "KCAxk6MsY9UC"
   },
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from defense import standard_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdRNu1LxcAGI"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24947,
     "status": "ok",
     "timestamp": 1694263772152,
     "user": {
      "displayName": "Niharika Shrivastava",
      "userId": "07199383378542377502"
     },
     "user_tz": -480
    },
    "id": "tJKv9Z5baBzD",
    "outputId": "1c1e6f0e-3675-4577-eea9-74b3733c71c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Training----------\n",
      "Train Err\tTrain Loss\tTest Err\tTest Loss\n",
      "0.325069\t-67.236302\t0.304019\t-135.218715\n",
      "0.320332\t-201.719023\t0.315839\t-269.596669\n",
      "0.319700\t-336.117538\t0.318676\t-403.971446\n",
      "0.321042\t-470.531108\t0.318676\t-538.285577\n",
      "0.319463\t-604.880684\t0.321040\t-672.597670\n",
      "0.319147\t-739.234940\t0.322459\t-806.948575\n",
      "0.319937\t-873.642724\t0.322931\t-941.284024\n",
      "0.320963\t-1008.013024\t0.321986\t-1075.471848\n",
      "0.320884\t-1142.237945\t0.321986\t-1209.864648\n",
      "0.322148\t-1276.664018\t0.318203\t-1344.102004\n",
      "---------result----------\n",
      "test error: 0.185343, loss 33.071336\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_data('mnist')\n",
    "robust_model = nn.Linear(784, 1)\n",
    "opt = optim.SGD(robust_model.parameters(), lr=1e-1)\n",
    "\n",
    "print(\"---------Training----------\")\n",
    "print(\"Train Err\", \"Train Loss\", \"Test Err\", \"Test Loss\", sep=\"\\t\")\n",
    "for i in range(10):\n",
    "    train_err, train_loss = robust_trainer(train_loader, robust_model, 0.01, opt)\n",
    "    test_err, test_loss = robust_trainer(test_loader, robust_model, 0.01)\n",
    "    print(*(\"{:.6f}\".format(i) for i in (train_err, train_loss, test_err, test_loss)), sep=\"\\t\")\n",
    "\n",
    "train_err, train_loss = standard_trainer(train_loader, robust_model)\n",
    "test_err, test_loss = standard_trainer(test_loader, robust_model)\n",
    "\n",
    "print(\"---------result----------\")\n",
    "print(\"test error: %0.6f, loss %0.6f\" % (test_err,test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxnbuJ5Jfymm"
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsBmH5duf1O9"
   },
   "source": [
    "## Write in the cell below about how you solved the inner optimization and the difficulties faced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fevPFICyf9AX"
   },
   "source": [
    "## Inner optimization\n",
    "\n",
    "1. Suppose the perturbation set is the $l_\\infty$ ball of size $ϵ$ around $x$. \\\\\n",
    "$ P_x = \\{x+δ : ||δ||_\\infty ≤ ϵ \\} $ \\\\\n",
    "\n",
    "2. The inner optimization objective is as follows: \\\\\n",
    "$max_{||δ||_\\infty ≤ ϵ}$ $\\{l(w^T (x + δ), y)\\} ≡$ $max_{||δ||_\\infty ≤ ϵ}$ $\\{L(y · (w^T (x + δ) + b)) \\}$ \\\\\n",
    "\n",
    "3. We know that, \\\\\n",
    "$L(y · h_θ(x)) = log(1 + exp(−y · h_θ(x)))$\n",
    "\n",
    "  Therefore, the inner optimization becomes: \\\\\n",
    "  $max_{||δ||_\\infty ≤ ϵ}$ $\\{ log(1 + exp(−y · (w^T (x + δ) + b))) \\}$\n",
    "\n",
    "4. Since the function $log(1 + exp(−z))$ is monotonically decreasing with respect to $z$, it can be further simplified as: \\\\\n",
    "      $min_{||δ||_\\infty ≤ ϵ}$ $\\{ y·w^Tδ \\}$\n",
    "\n",
    "5. Thus, the optimal perturbation is: \\\\\n",
    "$ δ^∗ = −y.ϵ sign(w) $.\n",
    "\n",
    "## Difficulties\n",
    "\n",
    "The assigment description states that we need to change $y \\in \\{-1, 1\\}$ for optimal perturbation calculation.\n",
    "\n",
    "I spent a lot of time trying to understand why we are projecting the classes to $\\{-1, 1\\}$ for calculating adversarial images, but using classes $\\{0, 1\\}$ for calculating outer optimization. Perhaps its because the sigmoid function inside `torch.BCELossWIthLogits` maps pred to $\\{0, 1\\}$.\n",
    "But then why not calculate the optimal perturbation for $\\{0, 1\\}$?\n",
    "\n",
    "I compared losses of all permutations:\n",
    "  1. $y ∈ \\{-1, 1\\}$ for optimal perturbation, $y ∈ \\{0, 1\\}$ for loss calculation.\n",
    "  2. $y ∈ \\{-1, 1\\}$ for optimal perturbation, $y ∈ \\{-1, 1\\}$ for loss calculation.\n",
    "  3. $y ∈ \\{0, 1\\}$ for optimal perturbation, $y ∈ \\{0, 1\\}$ for loss calculation.\n",
    "\n",
    "I have finally implemented (and reported) case 1. I understand that adversarial training in general reduces the utility of the model by some margin or keeps it same to normal training, and this result validates that.\n",
    "\n",
    "I also got this clarified on MS Teams.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tuSr1XwZoltM",
    "uxxbhSnbYvxd",
    "oxnbuJ5Jfymm"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
